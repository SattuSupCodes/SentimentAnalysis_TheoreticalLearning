{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SattuSupCodes/SentimentAnalysis_TheoreticalLearning/blob/main/diarisation_gender_basis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "q0aSGr8cO424"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.cluster import KMeans #from here we start out unsupervised checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ejlok1/cremad\")\n",
        "# ADDING MORE DATASETS TO ADD DYNAMICS LETS GO\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l0WUJY316PG",
        "outputId": "9953ab5f-3e17-4b60-b264-03d546a67f7f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ejlok1/cremad?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 451M/451M [00:03<00:00, 129MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/ejlok1/cremad/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding How Crema-D Dataset Works\n",
        "\n",
        "eg: 1001_TSI_SAD_XX.wav is actually the format [ActorID]_[Sentence]_[Emotion]_[Intensity].wav\n",
        " the CREMA-D is a very good dataset to use to ensure the model does not overfit. (Like what happened with our RAVDESS data here)\n",
        "\n",
        " # Gender\n",
        "\n",
        " CREMA-D uses actorID metadata to map gender.\n",
        " WE MUST USE THIS METADATA ONLY.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "NbrJK8wu2-RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlE8XJnH2XyS",
        "outputId": "fdee46bd-fc6f-4af3-fcba-f4abdd99c5be"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AudioWAV']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UHM...\n",
        " Nevermind, kaggle seems to have made some tweaks and the gender labels aren't there anymore so...\n",
        "\n",
        " # WE SWITCH FROM SUPERVISED -> UNSUPERVISED\n",
        " DO I HEAR EXTRA CHALLENGE? LETS GO"
      ],
      "metadata": {
        "id": "1YYWNqYLAR_d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WmEuLrnYR_n",
        "outputId": "f41e3ffb-0a11-47e7-fd9a-99a3a35adba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# os.listdir('/content/drive/MyDrive/ravdess')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zEaCyO6Gc0d9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qocEDJuJX3rR"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/drive/MyDrive/ravdess/audio_speech_actors_01-24\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# os.listdir(base_path)\n"
      ],
      "metadata": {
        "id": "lUz853rzdKD1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFbXp7hIYDZK"
      },
      "outputs": [],
      "source": [
        "def extract_mfcc(file_path, n_mfcc=13):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    mfcc_mean = np.mean(mfcc, axis=1)\n",
        "    mfcc_std = np.std(mfcc, axis=1)\n",
        "\n",
        "    return np.concatenate([mfcc_mean, mfcc_std])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WSn18R42YGqO"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for actor in os.listdir(base_path):\n",
        "    actor_path = os.path.join(base_path, actor)\n",
        "\n",
        "    if not os.path.isdir(actor_path):\n",
        "        continue\n",
        "\n",
        "    actor_id = int(actor.split(\"_\")[1])\n",
        "\n",
        "    gender_label = 1 if actor_id % 2 == 0 else 0  # 1=female, 0=male\n",
        "\n",
        "    for file in os.listdir(actor_path):\n",
        "        if file.endswith(\".wav\"):\n",
        "            file_path = os.path.join(actor_path, file)\n",
        "            features = extract_mfcc(file_path)\n",
        "\n",
        "            X.append(features)\n",
        "            y.append(gender_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Male samples:\", np.sum(y == 0))\n",
        "print(\"Female samples:\", np.sum(y == 1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbzhWxi7nk1K",
        "outputId": "b009e4f1-6cc8-436d-edb0-dcfce8c2fc4d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (1440, 26)\n",
            "y shape: (1440,)\n",
            "Male samples: 720\n",
            "Female samples: 720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "n504CG_unpSY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "pVxXW84qnsLS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKlF_s7enu-8",
        "outputId": "9a541aa7-3c3e-4706-c900-3acf0e145815"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9965277777777778\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00       144\n",
            "           1       0.99      1.00      1.00       144\n",
            "\n",
            "    accuracy                           1.00       288\n",
            "   macro avg       1.00      1.00      1.00       288\n",
            "weighted avg       1.00      1.00      1.00       288\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOnjWuDUoDRB",
        "outputId": "765be1d4-1fdf-4e11-95cb-a45179ad2974"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[143   1]\n",
            " [  0 144]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.bincount(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iJDAV1Ao4P_",
        "outputId": "27e09f4c-789e-451f-b776-c26a52352d80"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([720, 720])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Too Accurate?\n",
        "don't get happy, our dataset is too good. That's it. (sorry for bursting our bubble) [CHECKPOINT WHRE WE USED ONLY RAVDESS]"
      ],
      "metadata": {
        "id": "7TXsMvjaoIF1"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMclwpYpO4SxM6lOJxMikDr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}