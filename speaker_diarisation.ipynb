{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvXL4KJW1FwQoVPY+wafLA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SattuSupCodes/SentimentAnalysis_TheoreticalLearning/blob/main/speaker_diarisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jZyc0c89sd5V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy scipy librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FPgeFxUvwETM",
        "outputId": "2dfebfa7-b45b-4484-cd70-5b2166742c51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3xNRkzRwrUH",
        "outputId": "e2ce01aa-90c8-41d4-8485-d244735e74d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.1.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=fafd9547b4a5717feea0607871e6b783ad521bfdf3805aa0460a77d72ed843dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"sample.wav\")\n",
        "\n",
        "segments = result[\"segments\"]\n",
        "for seg in segments:\n",
        "    print(f\"{seg['start']:.2f}-{seg['end']:.2f}: {seg['text']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qBccyXzewyUk",
        "outputId": "17d6bff9-8f3b-414a-973f-80cf25191368"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 101MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00-5.52:  Just that was kind of the thought and whatever and then you hit me and I was like no frickin way\n",
            "5.52-9.40:  He's hitting me right now. So I was like absolutely. This is like perfect\n",
            "9.40-15.50:  It's the universe just putting it in perfect timing because that makes me so happy because it was exactly the opposite way\n",
            "15.50-21.76:  So I've for a long time had people that I'd love to sit down with and every time I saw you do something with mental health and\n",
            "21.76-26.54:  Vogue or any of the segments that you ever did I was just like she's amazing like you know\n",
            "26.54-29.66:  It's incredible to the way you were talking about it when you'd post about it\n",
            "29.66-33.82:  I'd be like oh this is incredible like this is see you speaking so openly about it\n",
            "33.82-39.74:  Invulnerably about it and so I've always wanted to do this and then but we've never really crossed paths\n",
            "39.74-44.54:  And so I'm always just a bit like and I don't like asking friends of friends when I haven't met someone and right\n",
            "44.54-47.22:  So I was like that day I had to like pluck up the card\n",
            "47.22-52.30:  I'm just gonna ask of myself no it's easier when I'm not starting and I know Christie's so yeah\n",
            "52.30-56.86:  Yeah, yeah, but I was like I it's nicer when there's I told my team too. I was like it's so much nicer when there's\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y, sr = librosa.load(\"sample.wav\", sr=None)\n"
      ],
      "metadata": {
        "id": "WDz0Oidfvzwh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segment_len = int(1.5 * sr)\n",
        "segments = [\n",
        "    y[i:i+segment_len]\n",
        "    for i in range(0, len(y), segment_len)\n",
        "    if len(y[i:i+segment_len]) == segment_len\n",
        "]\n"
      ],
      "metadata": {
        "id": "lIEji_0OwTE5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y, sr = librosa.load(\"sample.wav\", sr=None)\n",
        "\n",
        "segment_len_sec = 1.5\n",
        "segment_len = int(segment_len_sec * sr)\n",
        "\n",
        "segments_audio = [\n",
        "    y[i:i+segment_len]\n",
        "    for i in range(0, len(y), segment_len)\n",
        "    if len(y[i:i+segment_len]) == segment_len\n",
        "]\n"
      ],
      "metadata": {
        "id": "SZ4hf19OxBO1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc(seg, sr):\n",
        "    mfcc = librosa.feature.mfcc(y=seg, sr=sr, n_mfcc=13)\n",
        "    return np.mean(mfcc, axis=1)\n",
        "\n",
        "X = np.array([extract_mfcc(seg, sr) for seg in segments])\n"
      ],
      "metadata": {
        "id": "fPKwrSf-wVUG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mfcc_embed(seg, sr):\n",
        "    mfcc = librosa.feature.mfcc(y=seg, sr=sr, n_mfcc=13)\n",
        "    return np.mean(mfcc, axis=1)\n",
        "\n",
        "X = np.array([mfcc_embed(seg, sr) for seg in segments_audio])\n"
      ],
      "metadata": {
        "id": "yi1JzzQKxERu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agglomerative Clustering\n",
        "basically, we segmented our audio into many segments of 1.5 secs (we assume that thee spealers are consistent)\n",
        "\n",
        "then our already-existng (thank you python-gods) agglomerative clustering helps in \"this segment sounds very similar to this segment. CLUSTER\" and boom\n",
        "\n",
        "speaker 0 and speaker 1"
      ],
      "metadata": {
        "id": "Wecw7fVh2BZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "clusterer = AgglomerativeClustering(n_clusters=2)\n",
        "labels = clusterer.fit_predict(X)\n"
      ],
      "metadata": {
        "id": "joLZBawMwYfM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "labels = AgglomerativeClustering(n_clusters=2).fit_predict(X)\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "labels = AgglomerativeClustering(n_clusters=2).fit_predict(X)\n"
      ],
      "metadata": {
        "id": "jCU9XSWZxGqD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, label in enumerate(labels):\n",
        "    start = i * 1.5\n",
        "    end = start + 1.5\n",
        "    print(f\"{start:.1f}s - {end:.1f}s : Speaker {label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4EVHkxf7wbXS",
        "outputId": "d825849a-c820-4df1-f7ea-1da1af5607a0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0s - 1.5s : Speaker 0\n",
            "1.5s - 3.0s : Speaker 1\n",
            "3.0s - 4.5s : Speaker 1\n",
            "4.5s - 6.0s : Speaker 1\n",
            "6.0s - 7.5s : Speaker 1\n",
            "7.5s - 9.0s : Speaker 1\n",
            "9.0s - 10.5s : Speaker 1\n",
            "10.5s - 12.0s : Speaker 1\n",
            "12.0s - 13.5s : Speaker 0\n",
            "13.5s - 15.0s : Speaker 0\n",
            "15.0s - 16.5s : Speaker 0\n",
            "16.5s - 18.0s : Speaker 0\n",
            "18.0s - 19.5s : Speaker 0\n",
            "19.5s - 21.0s : Speaker 0\n",
            "21.0s - 22.5s : Speaker 0\n",
            "22.5s - 24.0s : Speaker 0\n",
            "24.0s - 25.5s : Speaker 0\n",
            "25.5s - 27.0s : Speaker 0\n",
            "27.0s - 28.5s : Speaker 0\n",
            "28.5s - 30.0s : Speaker 0\n",
            "30.0s - 31.5s : Speaker 0\n",
            "31.5s - 33.0s : Speaker 0\n",
            "33.0s - 34.5s : Speaker 0\n",
            "34.5s - 36.0s : Speaker 0\n",
            "36.0s - 37.5s : Speaker 1\n",
            "37.5s - 39.0s : Speaker 0\n",
            "39.0s - 40.5s : Speaker 1\n",
            "40.5s - 42.0s : Speaker 0\n",
            "42.0s - 43.5s : Speaker 1\n",
            "43.5s - 45.0s : Speaker 0\n",
            "45.0s - 46.5s : Speaker 1\n",
            "46.5s - 48.0s : Speaker 1\n",
            "48.0s - 49.5s : Speaker 1\n",
            "49.5s - 51.0s : Speaker 1\n",
            "51.0s - 52.5s : Speaker 1\n",
            "52.5s - 54.0s : Speaker 1\n",
            "54.0s - 55.5s : Speaker 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels.flatten()\n",
        "\n",
        "def assign_speaker(start_time):\n",
        "    idx = int(start_time / segment_len_sec)\n",
        "    if idx < 0 or idx >= len(labels):\n",
        "        return -1\n",
        "    return int(labels[idx])\n",
        "\n",
        "for seg in result[\"segments\"]:\n",
        "    spk = assign_speaker(seg[\"start\"])\n",
        "    print(f\"[Speaker {spk}] {seg['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y600hzn0xJAL",
        "outputId": "3db70a2e-c45f-4a7a-bde8-965f6b8ef181"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Speaker 0]  Just that was kind of the thought and whatever and then you hit me and I was like no frickin way\n",
            "[Speaker 1]  He's hitting me right now. So I was like absolutely. This is like perfect\n",
            "[Speaker 1]  It's the universe just putting it in perfect timing because that makes me so happy because it was exactly the opposite way\n",
            "[Speaker 0]  So I've for a long time had people that I'd love to sit down with and every time I saw you do something with mental health and\n",
            "[Speaker 0]  Vogue or any of the segments that you ever did I was just like she's amazing like you know\n",
            "[Speaker 0]  It's incredible to the way you were talking about it when you'd post about it\n",
            "[Speaker 0]  I'd be like oh this is incredible like this is see you speaking so openly about it\n",
            "[Speaker 0]  Invulnerably about it and so I've always wanted to do this and then but we've never really crossed paths\n",
            "[Speaker 1]  And so I'm always just a bit like and I don't like asking friends of friends when I haven't met someone and right\n",
            "[Speaker 0]  So I was like that day I had to like pluck up the card\n",
            "[Speaker 1]  I'm just gonna ask of myself no it's easier when I'm not starting and I know Christie's so yeah\n",
            "[Speaker 1]  Yeah, yeah, but I was like I it's nicer when there's I told my team too. I was like it's so much nicer when there's\n"
          ]
        }
      ]
    }
  ]
}